# -*- coding: utf-8 -*-
"""DenoisingAutoencode_task1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14IX-NLjaQoD7rVToqsgTQZk59mw7nyiJ
"""

! pip install openai

# Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.optim as optim

import openai
import requests
from PIL import Image
from io import BytesIO

"""new code"""

from google.colab import files

uploaded = files.upload()

import os

# List files in current directory
for filename in uploaded.keys():
    print(filename)

import os
from shutil import move

dataset_dir = "bike_dataset"
os.makedirs(dataset_dir, exist_ok=True)

# Move all image files into the folder
for filename in os.listdir():
    if filename.lower().endswith((".jpg", ".jpeg", ".png")):
        if not os.path.isdir(filename):  # Avoid moving folders
            move(filename, os.path.join(dataset_dir, filename))

print("✅ All image files moved to:", dataset_dir)



def add_gaussian_noise(images, sigma=0.3):
    noise = torch.randn_like(images) * sigma
    noisy = images + noise
    return torch.clamp(noisy, 0., 1.)

# Apply noise
noisy_images_tensor = add_gaussian_noise(clean_images_tensor, sigma=0.3)

# Show original vs noisy
def show_original_vs_noisy(clean, noisy, n=10):
    plt.figure(figsize=(15, 4))
    for i in range(n):
        # Original
        plt.subplot(2, n, i+1)
        plt.imshow(clean[i].squeeze(), cmap='gray')
        plt.axis('off')
        # Noisy
        plt.subplot(2, n, i+1+n)
        plt.imshow(noisy[i].squeeze(), cmap='gray')
        plt.axis('off')
    plt.suptitle("Original (Top) vs Noisy (Bottom)", fontsize=16)
    plt.tight_layout()
    plt.show()

# Display the first 10 images
show_original_vs_noisy(clean_images_tensor, noisy_images_tensor)

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader

# Split into train/test sets
split = int(0.8 * len(clean_images_tensor))
train_clean = clean_images_tensor[:split]
train_noisy = noisy_images_tensor[:split]

test_clean = clean_images_tensor[split:]
test_noisy = noisy_images_tensor[split:]

# Create PyTorch datasets
train_dataset = TensorDataset(train_noisy, train_clean)
test_dataset = TensorDataset(test_noisy, test_clean)

# Loaders
train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)

class DenoisingAutoencoder(nn.Module):
    def __init__(self):
        super().__init__()
        # Encoder
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 32, 3, stride=2, padding=1),  # [B, 32, 32, 32]
            nn.ReLU(),
            nn.Conv2d(32, 64, 3, stride=2, padding=1), # [B, 64, 16, 16]
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, stride=2, padding=1), # [B, 128, 8, 8]
            nn.ReLU(),
            nn.Conv2d(128, 256, 3, stride=2, padding=1), # [B, 256, 4, 4]
            nn.ReLU()
        )
        # Decoder
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(32, 1, 3, stride=2, padding=1, output_padding=1),
            nn.Sigmoid()
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

model = DenoisingAutoencoder().to("cuda" if torch.cuda.is_available() else "cpu")

device = "cuda" if torch.cuda.is_available() else "cpu"
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=1e-3)

num_epochs = 800
train_losses = []

for epoch in range(num_epochs):
    model.train()
    epoch_loss = 0.0
    for noisy, clean in train_loader:
        noisy = noisy.to(device)
        clean = clean.to(device)

        output = model(noisy)
        loss = criterion(output, clean)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item()

    avg_loss = epoch_loss / len(train_loader)
    train_losses.append(avg_loss)
    print(f"Epoch {epoch+1}/{num_epochs} | Loss: {avg_loss:.4f}")

import matplotlib.pyplot as plt

plt.plot(train_losses)
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training Loss over Epochs")
plt.grid(True)
plt.show()

def visualize_results(clean, noisy, denoised, n=10):
    """
    Displays clean, noisy, and denoised image samples in a grid.

    Args:
        clean (Tensor): Clean original images [N, 1, H, W]
        noisy (Tensor): Noisy input images [N, 1, H, W]
        denoised (Tensor): Output from the autoencoder [N, 1, H, W]
        n (int): Number of images to display (max 10 recommended)
    """

    # Ensure n does not exceed the available number of images
    n = min(n, clean.shape[0])

    # Create a figure with enough width and height for 3 rows
    plt.figure(figsize=(2.5 * n, 10))  # Width scales with number of columns (n)

    for i in range(n):
        # Row 1: Clean image
        plt.subplot(3, n, i + 1)  # Top row (clean images)
        plt.imshow(clean[i].squeeze().cpu(), cmap='gray')
        plt.axis('off')

        # Row 2: Noisy image
        plt.subplot(3, n, i + 1 + n)  # Middle row (noisy input)
        plt.imshow(noisy[i].squeeze().cpu(), cmap='gray')
        plt.axis('off')

        # Row 3: Denoised output
        plt.subplot(3, n, i + 1 + 2 * n)  # Bottom row (autoencoder output)
        plt.imshow(denoised[i].squeeze().cpu(), cmap='gray')
        plt.axis('off')

    # Add a descriptive title and optimize layout
    plt.suptitle("Clean (Top) | Noisy (Middle) | Denoised (Bottom)", fontsize=18)
    plt.tight_layout()
    plt.show()

# Take 10 samples from the full dataset for visualization
clean_batch = clean_images_tensor[:10]
noisy_batch = noisy_images_tensor[:10].to(device)

# Get denoised output from the trained model
with torch.no_grad():
    denoised_batch = model(noisy_batch)

# Show results in a 3-row grid: clean, noisy, denoised
visualize_results(clean_batch, noisy_batch.cpu(), denoised_batch.cpu(), n=10)

"""### **Result Visualization**

The figure above compares the original, noisy, and denoised grayscale images. The denoising autoencoder successfully reconstructs the overall structure of each image even under heavy Gaussian noise.

- **Top row:** Original clean images
- **Middle row:** Noisy images with added zero-mean Gaussian noise (σ = 0.4)
- **Bottom row:** Output of the denoising autoencoder

We can observe that the denoised images are significantly cleaner than the noisy versions, preserving meaningful visual features. Some fine details are still lost due to high noise, but the model performs well overall.

"""